{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Project description\n",
    "Mobile carrier Megaline has found out that many of their subscribers use legacy plans. They want to develop a model that would analyze subscribers' behavior and recommend one of Megaline's newer plans: Smart or Ultra.\n",
    "You have access to behavior data about subscribers who have already switched to the new plans (from the project for the Statistical Data Analysis course). For this classification task, you need to develop a model that will pick the right plan. Since you’ve already performed the data preprocessing step, you can move straight to creating the model.\n",
    "Develop a model with the highest possible accuracy. In this project, the threshold for accuracy is 0.75. Check the accuracy using the test dataset."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Open and look through the data file. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>calls</th>\n",
       "      <th>minutes</th>\n",
       "      <th>messages</th>\n",
       "      <th>mb_used</th>\n",
       "      <th>is_ultra</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>40.0</td>\n",
       "      <td>311.90</td>\n",
       "      <td>83.0</td>\n",
       "      <td>19915.42</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>85.0</td>\n",
       "      <td>516.75</td>\n",
       "      <td>56.0</td>\n",
       "      <td>22696.96</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>77.0</td>\n",
       "      <td>467.66</td>\n",
       "      <td>86.0</td>\n",
       "      <td>21060.45</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>106.0</td>\n",
       "      <td>745.53</td>\n",
       "      <td>81.0</td>\n",
       "      <td>8437.39</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>66.0</td>\n",
       "      <td>418.74</td>\n",
       "      <td>1.0</td>\n",
       "      <td>14502.75</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3209</td>\n",
       "      <td>122.0</td>\n",
       "      <td>910.98</td>\n",
       "      <td>20.0</td>\n",
       "      <td>35124.90</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3210</td>\n",
       "      <td>25.0</td>\n",
       "      <td>190.36</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3275.61</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3211</td>\n",
       "      <td>97.0</td>\n",
       "      <td>634.44</td>\n",
       "      <td>70.0</td>\n",
       "      <td>13974.06</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3212</td>\n",
       "      <td>64.0</td>\n",
       "      <td>462.32</td>\n",
       "      <td>90.0</td>\n",
       "      <td>31239.78</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3213</td>\n",
       "      <td>80.0</td>\n",
       "      <td>566.09</td>\n",
       "      <td>6.0</td>\n",
       "      <td>29480.52</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3214 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      calls  minutes  messages   mb_used  is_ultra\n",
       "0      40.0   311.90      83.0  19915.42         0\n",
       "1      85.0   516.75      56.0  22696.96         0\n",
       "2      77.0   467.66      86.0  21060.45         0\n",
       "3     106.0   745.53      81.0   8437.39         1\n",
       "4      66.0   418.74       1.0  14502.75         0\n",
       "...     ...      ...       ...       ...       ...\n",
       "3209  122.0   910.98      20.0  35124.90         1\n",
       "3210   25.0   190.36       0.0   3275.61         0\n",
       "3211   97.0   634.44      70.0  13974.06         0\n",
       "3212   64.0   462.32      90.0  31239.78         0\n",
       "3213   80.0   566.09       6.0  29480.52         1\n",
       "\n",
       "[3214 rows x 5 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "%matplotlib inline \n",
    "\n",
    "\n",
    "from sklearn.model_selection import train_test_split \n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "df = pd.read_csv('/datasets/users_behavior.csv')\n",
    "\n",
    "display(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3214, 5)\n",
      "\n",
      "The dataset has 3214 rows\n",
      "\n",
      "The dataset has 5 columns\n",
      "\n",
      "The dataset has 0 duplicates\n",
      "\n",
      "\n",
      "NaN in the whole dataset are:\n",
      "calls       0\n",
      "minutes     0\n",
      "messages    0\n",
      "mb_used     0\n",
      "is_ultra    0\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "#General information about dataset.\n",
    "\n",
    "print(df.shape)\n",
    "print()\n",
    "print('The dataset has {0}'.format(df.shape[0]), 'rows')\n",
    "print()\n",
    "print('The dataset has {0}'.format(df.shape[1]), 'columns')\n",
    "print()\n",
    "print('The dataset has {0}'.format(df.duplicated().sum()), 'duplicates')\n",
    "print()\n",
    "print()\n",
    "print('NaN in the whole dataset are:')\n",
    "print(df.isna().sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             calls      minutes     messages       mb_used     is_ultra\n",
      "count  3214.000000  3214.000000  3214.000000   3214.000000  3214.000000\n",
      "mean     63.038892   438.208787    38.281269  17207.673836     0.306472\n",
      "std      33.236368   234.569872    36.148326   7570.968246     0.461100\n",
      "min       0.000000     0.000000     0.000000      0.000000     0.000000\n",
      "25%      40.000000   274.575000     9.000000  12491.902500     0.000000\n",
      "50%      62.000000   430.600000    30.000000  16943.235000     0.000000\n",
      "75%      82.000000   571.927500    57.000000  21424.700000     1.000000\n",
      "max     244.000000  1632.060000   224.000000  49745.730000     1.000000\n",
      "\n",
      "The number of non-ultra customers is: 2229\n",
      "\n",
      "The number of ultra customers is: 985\n",
      "\n",
      "The percentage of non-ultra customers is: 69.35283136278781 %\n",
      "\n",
      "The percentage of ultra customers is: 30.647168637212197 %\n"
     ]
    }
   ],
   "source": [
    "print(df.describe())\n",
    "print()\n",
    "print('The number of non-ultra customers is:', df.is_ultra.loc[df.is_ultra == 0].count())\n",
    "print()\n",
    "print('The number of ultra customers is:', df.is_ultra.loc[df.is_ultra == 1].count())\n",
    "print()\n",
    "print('The percentage of non-ultra customers is:', (len(df.is_ultra.loc[df.is_ultra == 0])/len(df.is_ultra)*100),'%')\n",
    "print()\n",
    "print('The percentage of ultra customers is:', (len(df.is_ultra.loc[df.is_ultra == 1])/len(df.is_ultra)*100),'%')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0 0 0 ... 0 0 1]\n",
      "\n",
      "3214\n"
     ]
    }
   ],
   "source": [
    "#Creating a target variable.\n",
    "y_true = df.is_ultra.values\n",
    "\n",
    "#Printing how the variable itself + len of the variable.\n",
    "print(y_true)\n",
    "print()\n",
    "print(len(y_true)) #Should return the len of the starting dataframe."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Brief summarize. Task 1.\n",
    "1. Open and look through the data file. \n",
    "\n",
    "I opened the dataset reading the .csv file. We had an initial dataset of 3214 rows and 5 columns.\n",
    "The dataset has no duplicates and no NaN values.\n",
    "\n",
    "I checked the number of non-ultra (0) customers and ultra (1) customers.\n",
    "We have a percentage of non-ultra customers of:   69.35283136278781 %\n",
    "We have a percentage of ultra customers of:       30.64716863721219 %"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Split the source data into a training set, a validation set and a test set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Splitting the data into train and test.\n",
    "df_train, df_test = train_test_split(df, stratify=y_true, test_size=0.2, random_state=8)\n",
    "#Splitting the training dataset into train validation and cross validation.\n",
    "df_train, df_valid = train_test_split(df_train, test_size=0.2, random_state=8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of records in training dataset: 2056\n",
      "Number of records in cross validation dataset: 515\n",
      "Number of records in the test dataset: 643\n",
      "\n",
      "Train and Cross validation dataset are going to be used to build the model itself.\n",
      "Test is going to check the accuracy of our model output.\n"
     ]
    }
   ],
   "source": [
    "print('Number of records in training dataset:', df_train.shape[0])\n",
    "print('Number of records in cross validation dataset:', df_valid.shape[0])\n",
    "print('Number of records in the test dataset:', df_test.shape[0])\n",
    "print('')\n",
    "print('Train and Cross validation dataset are going to be used to build the model itself.')\n",
    "print('Test is going to check the accuracy of our model output.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "To make sure that our testing is going to have a positive result,\n",
      "We can save the column in a variable to be able, to compare that to the model results obtained.\n"
     ]
    }
   ],
   "source": [
    "print('To make sure that our testing is going to have a positive result,')\n",
    "print('We can save the column in a variable to be able, to compare that to the model results obtained.')\n",
    "\n",
    "checking_values = df_test.is_ultra #This is going to become the array to check the accuracy of our model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Creating features and targets for our model.\n",
    "features_train = df_train.drop(['is_ultra'], axis=1)\n",
    "target_train = df_train['is_ultra']\n",
    "features_valid = df_valid.drop(['is_ultra'], axis=1)\n",
    "target_valid = df_valid['is_ultra']\n",
    "features_test = df_test.drop(['is_ultra'], axis=1)\n",
    "target_test = df_test['is_ultra']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train dataset:\n",
      "0    0.695039\n",
      "1    0.304961\n",
      "Name: is_ultra, dtype: float64\n",
      "\n",
      "Validation dataset:\n",
      "0    0.687379\n",
      "1    0.312621\n",
      "Name: is_ultra, dtype: float64\n",
      "\n",
      "Testing array:\n",
      "0    0.693624\n",
      "1    0.306376\n",
      "Name: is_ultra, dtype: float64\n",
      "\n",
      "Our train, test and cv datasets, correspond almost perfectly to the whole dataset.\n"
     ]
    }
   ],
   "source": [
    "#Let's take a look to the distribution of is_ultra column in the three dataset.\n",
    "#The importance of this step, lies in the fact, that we should make sure, that everyone of our datasets (train,test,cv) \n",
    "#has at least a 25% of ultra customers in it. Our initial rate of percentage is 70/30 (whole dataset)\n",
    "#Otherwise the prediction of our model are going to be distorted.\n",
    "#To change this split is just necessary changing random_state parameter in train_test_split function.\n",
    "\n",
    "train_is_ultra_distribution = df_train['is_ultra'].value_counts(normalize=True)\n",
    "cv_is_ultra_distribution = df_valid['is_ultra'].value_counts(normalize=True)\n",
    "test_is_ultra_distribution =  checking_values.value_counts(normalize=True)\n",
    "\n",
    "print('Train dataset:')\n",
    "print(train_is_ultra_distribution)\n",
    "print()\n",
    "print('Validation dataset:')\n",
    "print(cv_is_ultra_distribution)\n",
    "print()\n",
    "print('Testing array:')\n",
    "print(test_is_ultra_distribution)\n",
    "print()\n",
    "print('Our train, test and cv datasets, correspond almost perfectly to the whole dataset.')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Brief summarize. Task 2.\n",
    "\n",
    "2. Split the source data into a training set, a validation set and a test set.\n",
    "Through train_test_split I splitted two times the dataset.\n",
    "\n",
    "The First time I splitted the entire dataframe: obtaining 80% of df_train and 20% of df_test. \n",
    "(percentages on the starting dataset)\n",
    "\n",
    "The Second time I splitted the train dataframe: obtaining 80% of df_train and 20% of df_valid. \n",
    "(percentages on the training dataset)\n",
    "\n",
    "The result of the split allow us to have 3 dataset: one for training, one for validation and another to test our model.\n",
    "The number of records in training dataset is 2056.\n",
    "The number of records in cross validation dataset is 515.\n",
    "The number of records in the test dataset is 643.\n",
    "\n",
    "I saved in checking_values variable the value of df_test.is_ultra, this allow us to compare the predictions with the real values we have in test dataset.\n",
    "\n",
    "After that I created variables for each of the 3 dataset containing features and target of our program and checked their distribution. I tried in doing this, many random_state values (finding in 8 the better one)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. Investigate the quality of different models by changing hyperparameters. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Since we need a classification model, going to implement a Classifier model.\n",
      "\n",
      "Our choice is going to be one from DecisionTreeClassifier / RandomForestClassifier / LogisticRegression\n"
     ]
    }
   ],
   "source": [
    "print('Since we need a classification model, going to implement a Classifier model.')\n",
    "print()\n",
    "print('Our choice is going to be one from DecisionTreeClassifier / RandomForestClassifier / LogisticRegression')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "max_depth = 1 : 0.7359223300970874\n",
      "max_depth = 2 : 0.7708737864077669\n",
      "max_depth = 3 : 0.7844660194174757\n",
      "max_depth = 4 : 0.7902912621359224\n",
      "max_depth = 5 : 0.7864077669902912\n",
      "max_depth = 6 : 0.7728155339805826\n",
      "max_depth = 7 : 0.7825242718446602\n",
      "max_depth = 8 : 0.7766990291262136\n",
      "max_depth = 9 : 0.7766990291262136\n",
      "\n",
      "The best possible option here is max_depth = 4. We found our tree depth.\n",
      "The best possible accuracy obtained within this loop is : 0.7902912621359224\n"
     ]
    }
   ],
   "source": [
    "#Finding accuracy score for DecisionTreeClassifier\n",
    "result = []\n",
    "\n",
    "for depth in range(1, 10):\n",
    "        model = DecisionTreeClassifier(random_state = 8, max_depth=depth)\n",
    "        # < create a model, specify max_depth=depth >\n",
    "        model.fit(features_train, target_train) # < train the model >\n",
    "        predictions_valid = model.predict(features_valid) # < find the predictions using validation set >        \n",
    "        print(\"max_depth =\", depth, \": \", end='')\n",
    "        acc = accuracy_score(target_valid, predictions_valid)\n",
    "        print(acc)\n",
    "        result.append(acc)\n",
    "print()\n",
    "print('The best possible option here is max_depth = 4. We found our tree depth.')\n",
    "print('The best possible accuracy obtained within this hyperparameter is :', max(result))\n",
    "\n",
    "\n",
    "#Depth of 3,4 and 5 gives us the best possible result (78/79%). \n",
    "#This is a good result but not that much, going to try to adopt another model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "max_leaf_nodes = 2 : 0.7359223300970874\n",
      "max_leaf_nodes = 3 : 0.7708737864077669\n",
      "max_leaf_nodes = 4 : 0.7844660194174757\n",
      "max_leaf_nodes = 5 : 0.7922330097087379\n",
      "max_leaf_nodes = 6 : 0.7922330097087379\n",
      "max_leaf_nodes = 7 : 0.7922330097087379\n",
      "max_leaf_nodes = 8 : 0.7922330097087379\n",
      "max_leaf_nodes = 9 : 0.7922330097087379\n",
      "\n",
      "The best possible option here is max_leaf_nodes = 5. We found the number of max leaf in a node.\n",
      "The best possible accuracy obtained within this loop is : 0.7922330097087379\n"
     ]
    }
   ],
   "source": [
    "model = DecisionTreeClassifier(random_state = 8, max_depth=4)\n",
    "result=[]\n",
    "\n",
    "for leafs in range(2, 10):\n",
    "        model = DecisionTreeClassifier(random_state = 8, max_depth=4, max_leaf_nodes=leafs)\n",
    "        # < create a model, specify max_depth=depth >\n",
    "        model.fit(features_train, target_train) # < train the model >\n",
    "        predictions_valid = model.predict(features_valid) # < find the predictions using validation set >\n",
    "\n",
    "        print(\"max_leaf_nodes =\", leafs, \": \", end='')\n",
    "        acc=accuracy_score(target_valid, predictions_valid)\n",
    "        print(acc)\n",
    "        result.append(acc)\n",
    "print()\n",
    "print('The best possible option here is max_leaf_nodes = 5. We found the number of max leaf in a node.')\n",
    "print('The best possible accuracy obtained tuning this hyperparameter is :', max(result))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "min_samples_leaf = 1 : 0.7922330097087379\n",
      "min_samples_leaf = 11 : 0.7922330097087379\n",
      "min_samples_leaf = 21 : 0.7922330097087379\n",
      "min_samples_leaf = 31 : 0.7844660194174757\n",
      "min_samples_leaf = 41 : 0.7825242718446602\n",
      "min_samples_leaf = 51 : 0.7766990291262136\n",
      "min_samples_leaf = 61 : 0.7766990291262136\n",
      "min_samples_leaf = 71 : 0.7766990291262136\n",
      "min_samples_leaf = 81 : 0.7805825242718447\n",
      "min_samples_leaf = 91 : 0.7708737864077669\n",
      "\n",
      "The best possible option here is min_samples_leaf = 21.\n",
      "The best possible accuracy obtained within this loop is : 0.7922330097087379\n"
     ]
    }
   ],
   "source": [
    "model = DecisionTreeClassifier(random_state = 8, max_depth=4, max_leaf_nodes=5)\n",
    "result=[]\n",
    "\n",
    "for min_samples in range(1, 100,10):\n",
    "        model = DecisionTreeClassifier(random_state = 8, max_depth=4, max_leaf_nodes=5, min_samples_leaf=min_samples)\n",
    "        # < create a model, specify max_depth=depth >\n",
    "        model.fit(features_train, target_train) # < train the model >\n",
    "        predictions_valid = model.predict(features_valid) # < find the predictions using validation set >\n",
    "\n",
    "        print(\"min_samples_leaf =\", min_samples, \": \", end='')\n",
    "        acc=accuracy_score(target_valid, predictions_valid)\n",
    "        print(acc)\n",
    "        result.append(acc)\n",
    "print()\n",
    "print('The best possible option here is min_samples_leaf = 21.')\n",
    "print('The best possible accuracy obtained tuning this hyperparameter is :', max(result))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy score of DecisionTreeClassifier model is: 0.7922330097087379\n",
      "\n",
      "Rmse for DecisionTreeClassifier (with max_depth=4) is: 0.45581464466519955\n",
      "\n",
      "\n",
      "\n",
      "The best possible DecisionTreeClassifier model is the following:\n",
      "\n",
      "DecisionTreeClassifier(class_weight=None, criterion='gini', max_depth=4,\n",
      "                       max_features=None, max_leaf_nodes=5,\n",
      "                       min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "                       min_samples_leaf=21, min_samples_split=2,\n",
      "                       min_weight_fraction_leaf=0.0, presort=False,\n",
      "                       random_state=8, splitter='best')\n"
     ]
    }
   ],
   "source": [
    "#Calculating rmse of DecisionTreeClassifier model for max_depth=4\n",
    "model = DecisionTreeClassifier(random_state = 8, max_depth=4, max_leaf_nodes=5, min_samples_leaf=21)\n",
    "model.fit(features_train, target_train) # < train the model >\n",
    "predictions_valid = model.predict(features_valid) # < find the predictions using validation set >\n",
    "\n",
    "acc = accuracy_score(target_valid, predictions_valid)\n",
    "print('Accuracy score of DecisionTreeClassifier model is:', acc) #the lowest, the best.\n",
    "print()\n",
    "rmse_tree = mean_squared_error(target_valid, predictions_valid)**0.5\n",
    "print('Rmse for DecisionTreeClassifier (with max_depth=4) is:', rmse_tree) #the lowest, the best.\n",
    "print()\n",
    "print()\n",
    "print()\n",
    "print('The best possible DecisionTreeClassifier model is the following:')\n",
    "print()\n",
    "print(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "n_estimators = 10 Rmse: 0.4294950749630032\n",
      "n_estimators = 10 Accuracy: 0.8155339805825242\n",
      "\n",
      "n_estimators = 15 Rmse: 0.4384438501207855\n",
      "n_estimators = 15 Accuracy: 0.8077669902912621\n",
      "\n",
      "n_estimators = 20 Rmse: 0.44065264923923175\n",
      "n_estimators = 20 Accuracy: 0.8058252427184466\n",
      "\n",
      "n_estimators = 25 Rmse: 0.43622386699482907\n",
      "n_estimators = 25 Accuracy: 0.8097087378640777\n",
      "\n",
      "n_estimators = 30 Rmse: 0.44065264923923175\n",
      "n_estimators = 30 Accuracy: 0.8058252427184466\n",
      "\n",
      "n_estimators = 35 Rmse: 0.44065264923923175\n",
      "n_estimators = 35 Accuracy: 0.8058252427184466\n",
      "\n",
      "n_estimators = 40 Rmse: 0.44065264923923175\n",
      "n_estimators = 40 Accuracy: 0.8058252427184466\n",
      "\n",
      "n_estimators = 45 Rmse: 0.44065264923923175\n",
      "n_estimators = 45 Accuracy: 0.8058252427184466\n",
      "\n",
      "n_estimators = 50 Rmse: 0.4472135954999579\n",
      "n_estimators = 50 Accuracy: 0.8\n",
      "\n",
      "The best possible accuracy obtained tuning this hyperparameter is : 0.8155339805825242\n"
     ]
    }
   ],
   "source": [
    "#Finding Rmse for RandomForestClassifier, criterion=gini\n",
    "result=[]\n",
    "\n",
    "for estim in range(10, 51, 5):\n",
    "        model = RandomForestClassifier(n_estimators=estim, max_depth=10, random_state=8)\n",
    "        model.fit(features_train, target_train) # < train the model >\n",
    "        predictions_valid = model.predict(features_valid) \n",
    "        # < write code here >\n",
    "        \n",
    "        acc = accuracy_score(target_valid, predictions_valid)\n",
    "        rmse = mean_squared_error(target_valid, predictions_valid)**0.5\n",
    "        print(\"n_estimators =\", estim, \"Rmse:\", rmse)\n",
    "        print('n_estimators =', estim, 'Accuracy:', acc)\n",
    "        result.append(acc)\n",
    "        print()\n",
    "        \n",
    "print('The best possible accuracy obtained tuning this hyperparameter is :', max(result))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "n_estimators = 10 Rmse: 0.4384438501207855\n",
      "n_estimators = 10 Accuracy: 0.8077669902912621\n",
      "\n",
      "n_estimators = 15 Rmse: 0.45153460016440716\n",
      "n_estimators = 15 Accuracy: 0.7961165048543689\n",
      "\n",
      "n_estimators = 20 Rmse: 0.45153460016440716\n",
      "n_estimators = 20 Accuracy: 0.7961165048543689\n",
      "\n",
      "n_estimators = 25 Rmse: 0.442850431697169\n",
      "n_estimators = 25 Accuracy: 0.8038834951456311\n",
      "\n",
      "n_estimators = 30 Rmse: 0.4384438501207855\n",
      "n_estimators = 30 Accuracy: 0.8077669902912621\n",
      "\n",
      "n_estimators = 35 Rmse: 0.44503736070939537\n",
      "n_estimators = 35 Accuracy: 0.8019417475728156\n",
      "\n",
      "n_estimators = 40 Rmse: 0.44503736070939537\n",
      "n_estimators = 40 Accuracy: 0.8019417475728156\n",
      "\n",
      "n_estimators = 45 Rmse: 0.44065264923923175\n",
      "n_estimators = 45 Accuracy: 0.8058252427184466\n",
      "\n",
      "n_estimators = 50 Rmse: 0.442850431697169\n",
      "n_estimators = 50 Accuracy: 0.8038834951456311\n",
      "\n",
      "The best possible accuracy obtained tuning this hyperparameter is : 0.8077669902912621\n",
      "I will esclude entropy criterion in favor of Gini.\n"
     ]
    }
   ],
   "source": [
    "#Finding rmse for RandomForestClassifier, criterion=entropy\n",
    "result=[]\n",
    "\n",
    "for estim in range(10, 51, 5):\n",
    "        model = RandomForestClassifier(n_estimators=estim, criterion='entropy',max_depth=10, random_state=8)\n",
    "        model.fit(features_train, target_train) # < train the model >\n",
    "        predictions_valid = model.predict(features_valid) \n",
    "        # < write code here >\n",
    "\n",
    "        acc = accuracy_score(target_valid, predictions_valid)\n",
    "        rmse = mean_squared_error(target_valid, predictions_valid)**0.5\n",
    "        print(\"n_estimators =\", estim, \"Rmse:\", rmse)\n",
    "        print('n_estimators =', estim, 'Accuracy:', acc)\n",
    "        result.append(acc)\n",
    "        print()\n",
    "\n",
    "print('The best possible accuracy obtained tuning this hyperparameter is :', max(result))\n",
    "print('I will esclude entropy criterion in favor of Gini.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rmse for RandomForestClassifier (criterion=gini and n_estimators=10) is: 0.4294950749630032\n",
      "Accuracy score for RandomForestClassifier (n_estimators=10) is: 0.8155339805825242\n"
     ]
    }
   ],
   "source": [
    "model = RandomForestClassifier(n_estimators=10,max_depth=10, random_state=8)\n",
    "model.fit(features_train, target_train) # < train the model >\n",
    "predictions_valid = model.predict(features_valid) \n",
    "\n",
    "acc_forest = accuracy_score(target_valid, predictions_valid)\n",
    "rmse_forest = mean_squared_error(target_valid, predictions_valid)**0.5\n",
    "print('Rmse for RandomForestClassifier (criterion=gini and n_estimators=10) is:', rmse_forest) #the lowest, the best.\n",
    "print('Accuracy score for RandomForestClassifier (n_estimators=10) is:', acc_forest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logistic regression rmse: 0.5287831790870781\n",
      "Logistic regression accuracy: 0.7203883495145631\n"
     ]
    }
   ],
   "source": [
    "#Finding Rmse values for LogisticRegression\n",
    "\n",
    "model = LogisticRegression(random_state=8, solver='liblinear', max_iter=100)\n",
    "model.fit(features_train, target_train) # < train the model >\n",
    "predictions_valid = model.predict(features_valid) \n",
    "\n",
    "acc_logistic = accuracy_score(target_valid, predictions_valid)\n",
    "rmse_logistic = mean_squared_error(target_valid, predictions_valid)**0.5\n",
    "print(\"Logistic regression rmse:\", rmse_logistic) \n",
    "print('Logistic regression accuracy:', acc_logistic)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Intercept scaling = 1 Rmse: 0.5287831790870781\n",
      "Intercept scaling= 1 Accuracy 0.7203883495145631\n",
      "\n",
      "Intercept scaling = 2 Rmse: 0.5269439276741135\n",
      "Intercept scaling= 2 Accuracy 0.7223300970873786\n",
      "\n",
      "Intercept scaling = 3 Rmse: 0.5269439276741135\n",
      "Intercept scaling= 3 Accuracy 0.7223300970873786\n",
      "\n",
      "Intercept scaling = 4 Rmse: 0.5269439276741135\n",
      "Intercept scaling= 4 Accuracy 0.7223300970873786\n",
      "\n",
      "Intercept scaling = 5 Rmse: 0.5269439276741135\n",
      "Intercept scaling= 5 Accuracy 0.7223300970873786\n",
      "\n",
      "Intercept scaling = 6 Rmse: 0.5250982339903705\n",
      "Intercept scaling= 6 Accuracy 0.7242718446601941\n",
      "\n",
      "Intercept scaling = 7 Rmse: 0.5269439276741135\n",
      "Intercept scaling= 7 Accuracy 0.7223300970873786\n",
      "\n",
      "Intercept scaling = 8 Rmse: 0.5269439276741135\n",
      "Intercept scaling= 8 Accuracy 0.7223300970873786\n",
      "\n",
      "Intercept scaling = 9 Rmse: 0.5250982339903705\n",
      "Intercept scaling= 9 Accuracy 0.7242718446601941\n",
      "\n",
      "\n",
      "Optimal scale value equal to 6.\n",
      "The best possible accuracy obtained tuning this hyperparameter is : 0.7242718446601941\n"
     ]
    }
   ],
   "source": [
    "result=[]\n",
    "for scale in range(1, 10):\n",
    "        model = LogisticRegression(random_state=8, solver='liblinear', max_iter=100, intercept_scaling=scale)\n",
    "        model.fit(features_train, target_train) # < train the model >\n",
    "        predictions_valid = model.predict(features_valid) \n",
    "        # < write code here >\n",
    "        acc = accuracy_score(target_valid, predictions_valid)\n",
    "        rmse = mean_squared_error(target_valid, predictions_valid)**0.5\n",
    "        print(\"Intercept scaling =\", scale, \"Rmse:\", rmse)\n",
    "        print('Intercept scaling=', scale, 'Accuracy', acc)\n",
    "        result.append(acc)\n",
    "        print()\n",
    "print()\n",
    "print('Optimal scale value equal to 6.')\n",
    "print('The best possible accuracy obtained tuning this hyperparameter is :', max(result))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy score is: 0.7262135922330097\n",
      "RMSE value is : 0.5232460298626167\n",
      "\n",
      "\n",
      "Optimal LogisticRegression model is:\n",
      "\n",
      "LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
      "                   intercept_scaling=6, l1_ratio=None, max_iter=100,\n",
      "                   multi_class='warn', n_jobs=None, penalty='l1',\n",
      "                   random_state=8, solver='liblinear', tol=0.0001, verbose=0,\n",
      "                   warm_start=False)\n",
      "\n",
      "Going to esclude LogisticRegression model since its values are much lower then other kind of models.\n"
     ]
    }
   ],
   "source": [
    "model = LogisticRegression(random_state=8, solver='liblinear', max_iter=100, intercept_scaling=6, penalty='l1')\n",
    "model.fit(features_train, target_train) # < train the model >\n",
    "predictions_valid = model.predict(features_valid) \n",
    "        # < write code here >\n",
    "\n",
    "acc_logistic = accuracy_score(target_valid, predictions_valid)\n",
    "rmse = mean_squared_error(target_valid, predictions_valid)**0.5\n",
    "print('Accuracy score is:', acc_logistic)\n",
    "print(\"RMSE value is :\", rmse) \n",
    "print()\n",
    "print()\n",
    "print('Optimal LogisticRegression model is:')\n",
    "print()\n",
    "print(model)\n",
    "print()\n",
    "print('Going to esclude LogisticRegression model since its values are much lower then other kind of models.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# I choose RandomForestClassifier as training model for the dataset. Now I am going to test all the values for\n",
    "# RandomForestClassifier, in order to find the best model possible.\n",
    "\n",
    "#Creating a parameters dictionary for possible hyperparameters values.\n",
    "parameters = { 'random_state' : (8,10),\n",
    "              'n_estimators': (5,10),\n",
    "              'criterion': ('gini','entropy'),\n",
    "              'max_depth': (10,5),\n",
    "              'max_features': ('auto','sqrt'),\n",
    "              } \n",
    "\n",
    "#Creating a grid model.\n",
    "RF_grid = GridSearchCV(RandomForestClassifier(), param_grid=parameters, cv=5) #THIS WILL TAKE REALLY LONG TIME TO EXECUTE.\n",
    "RF_grid_model = RF_grid.fit(features_train, target_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
      "                       max_depth=10, max_features='auto', max_leaf_nodes=None,\n",
      "                       min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "                       min_samples_leaf=1, min_samples_split=2,\n",
      "                       min_weight_fraction_leaf=0.0, n_estimators=10,\n",
      "                       n_jobs=None, oob_score=False, random_state=8, verbose=0,\n",
      "                       warm_start=False)\n"
     ]
    }
   ],
   "source": [
    "print(RF_grid_model.best_estimator_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy score: 0.8044747081712063\n"
     ]
    }
   ],
   "source": [
    "#Grid Model accuracy score.\n",
    "print('Accuracy score:',RF_grid_model.best_score_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE value is : 0.4294950749630032\n"
     ]
    }
   ],
   "source": [
    "predictions_valid = RF_grid_model.predict(features_valid) \n",
    "        # < write code here >\n",
    "\n",
    "rmse = mean_squared_error(target_valid, predictions_valid)**0.5\n",
    "print(\"RMSE value is :\", rmse)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GridSearchCV(cv=5, error_score='raise-deprecating',\n",
      "             estimator=RandomForestClassifier(bootstrap=True, class_weight=None,\n",
      "                                              criterion='gini', max_depth=None,\n",
      "                                              max_features='auto',\n",
      "                                              max_leaf_nodes=None,\n",
      "                                              min_impurity_decrease=0.0,\n",
      "                                              min_impurity_split=None,\n",
      "                                              min_samples_leaf=1,\n",
      "                                              min_samples_split=2,\n",
      "                                              min_weight_fraction_leaf=0.0,\n",
      "                                              n_estimators='warn', n_jobs=None,\n",
      "                                              oob_score=False,\n",
      "                                              random_state=None, verbose=0,\n",
      "                                              warm_start=False),\n",
      "             iid='warn', n_jobs=None,\n",
      "             param_grid={'criterion': ('gini', 'entropy'), 'max_depth': (10, 5),\n",
      "                         'max_features': ('auto', 'sqrt'),\n",
      "                         'n_estimators': (5, 10), 'random_state': (8, 10)},\n",
      "             pre_dispatch='2*n_jobs', refit=True, return_train_score=False,\n",
      "             scoring=None, verbose=0)\n"
     ]
    }
   ],
   "source": [
    "model = RF_grid_model\n",
    "print(model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Brief summarize. Task 3.\n",
    "3. Investigate the quality of different models by changing hyperparameters. Briefly describe the findings of the study.\n",
    "\n",
    "First of all I understood we needed classification models and not regression ones. Cause our target is a binary classification. If we have to 'label' our target classification models perform tasks better.\n",
    "\n",
    "I started from a DecisionTreeClassifier, with a really simple loop I watched trough the depth of our tree, finding in 4 its optimal depth, I did the same for max_leafs_nodes parameter finding in 5 our optimal value. Furthermore, checked for the min_samples_leaf parameter, I decided to choose 21. (21 in this case, is a better value then 1 or 11 cause even if the accuracy score is the same, a low value in this parameter could lead us to overfit our model.)\n",
    "\n",
    "Having this DecisionTreeClassifier model I obtained an accuracy of 0.7922330097087379 and an Rmse of 0.45581464466519955.\n",
    "\n",
    "After that I created a RandomForestClassifier model, I checked the hyperparameters as before finding in Gini the best criterion, in 10 the perfect number of estimators.\n",
    "\n",
    "Having this RandomForestClassifier model I obtained an accuracy of 0.8155339805825242 and an Rmse of 0.4294950749630032.\n",
    "\n",
    "I created as well a LogisticRegression model\n",
    "\n",
    "Since the accuracy of this model was 0.7203883495145631 and the Rmse was 0.5287831790870781, I decided to don't go further in tuning the hyperparameters.\n",
    "\n",
    "Decided that Random Forest Classifier was the best model to take in consideration, I created a dictionary to check many possible values at time for my model. Resulted in a final RandomForest model named 'RF_grid_model'.\n",
    "\n",
    "This model has an accuracy of 0.8044747081712063 and an Rmse value of 0.4294950749630032."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4. Check the quality of the model using the test set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Testing the best model on the test dataset.\n",
    "model = RandomForestClassifier(n_estimators=10,max_depth=10, random_state=8)\n",
    "model.fit(features_train, target_train) # < train the model >\n",
    "predictions_test = model.predict(features_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test: 0.810\n",
      "Train: 0.879\n",
      "\n",
      "This model, obtained an 81% accuracy on test dataset, while 87% on the trained dataset.\n"
     ]
    }
   ],
   "source": [
    "print(f'Test: {model.score(features_test, target_test):.3f}')\n",
    "print(f'Train: {model.score(features_train, target_train):.3f}')\n",
    "print()\n",
    "print('This model, obtained an 81% accuracy on test dataset, while 87% on the trained dataset.')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Brief summarize. Task 4.\n",
    "4. Check the quality of the model using the test set.\n",
    "\n",
    "While the accuracy of the model on the validation dataset is 80,44%. The accuracy obtained on the test dataset is 81,0% and the accuracy on the training dataset is 87,9%. This is normal cause obviously the model is more accurate on the training dataset, since it was trained on it."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 5. Additional task: sanity check the model. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0 0 0 0 1 0 0 0 0 0 0 1 0 1 1 0 0 0 0 1 1 0 0 0 0 0 1 1 0 1 1 0 0 0 0 1 0\n",
      " 0 0 0 0 0 0 0 0 0 1 0 0 1 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0\n",
      " 1 0 0 0 0 1 1 1 0 0 0 0 0 0 1 1 0 0 0 0 1 0 1 0 0 1 0 0 0 0 0 1 0 0 1 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0\n",
      " 0 1 0 0 0 0 0 1 0 0 0 0 0 0 1 0 0 1 1 1 0 0 0 0 1 0 0 1 1 0 0 1 0 0 0 0 0\n",
      " 0 1 0 0 0 0 0 1 0 0 0 0 0 1 0 0 0 1 0 0 1 0 0 0 1 1 1 0 0 1 0 0 0 0 1 1 0\n",
      " 0 0 0 0 1 0 0 0 1 0 1 0 0 0 0 0 0 0 1 1 0 0 1 0 0 0 0 0 0 1 0 1 0 0 0 1 1\n",
      " 1 1 0 0 0 0 0 0 0 0 0 0 0 0 1 1 0 0 0 1 0 0 1 0 0 0 0 0 0 0 0 0 0 0 1 0 0\n",
      " 0 1 0 0 0 0 0 0 0 0 0 0 0 1 0 0 1 1 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 1 0\n",
      " 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 1 1 0 0 1 0 0 0 1 0 0 0 0 1 0 0 0 1\n",
      " 0 0 0 0 1 0 0 0 1 0 0 0 0 0 0 0 1 0 1 1 0 1 0 0 0 0 0 0 0 0 0 1 0 1 1 0 0\n",
      " 0 0 0 1 0 1 1 1 0 0 0 1 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 1 1 0 0 0 0 0 0 0 1 0 0 0 1 0 0 0 0 1 0 1 0 0 0 1 1 0 0 0 1 0 0 0\n",
      " 0 0 0 1 0 0 0 0 0 0 1 0 0 1 0 0 0 0 0 0 0 0 0 0 0 1 1 0 1 0 0 1 0 0 0 1 0\n",
      " 1 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 0 1 1 0 1 1 0 0 1 0 0\n",
      " 0 0 0 0 1 1 0 0 1 0 0 0 0 0 1 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 1 0 0 0 0 1\n",
      " 0 0 0 1 0 0 0 0 0 0 0 0 0 1 1 0 1 0 0 0 0 0 0 0 1 0 0 1 0 0 0 0 0 0 0 0 1\n",
      " 0 0 0 0 0 0 0 0 0 0 1 0 1 0]\n",
      "643\n"
     ]
    }
   ],
   "source": [
    "#SANITY CHECK.\n",
    "#Predictions array.\n",
    "print(predictions_test)\n",
    "print(len(predictions_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1 0 1 1 1 0 0 0 0 0 0 1 0 0 1 0 0 0 1 1 1 0 0 0 0 0 1 1 1 0 1 1 1 0 0 1 0\n",
      " 0 1 0 0 1 0 0 0 0 1 0 0 1 0 1 0 0 0 0 0 0 1 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0\n",
      " 0 1 0 0 1 1 1 1 0 1 0 0 1 0 1 1 0 0 1 0 0 0 0 0 1 1 0 0 0 0 1 0 1 0 1 1 0\n",
      " 0 1 0 0 0 0 0 0 0 0 0 0 1 1 0 0 0 1 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 1 0\n",
      " 1 0 0 0 1 0 1 1 0 1 0 0 0 0 1 1 0 0 1 1 1 0 1 0 1 0 0 1 1 0 0 1 0 0 0 0 0\n",
      " 0 1 0 1 0 1 0 1 0 0 1 1 0 1 0 0 0 1 0 0 1 1 0 0 0 1 1 0 0 1 1 0 0 0 0 1 0\n",
      " 0 0 0 0 0 0 0 0 1 1 1 1 0 0 0 0 0 0 1 1 0 0 1 0 0 0 0 0 0 1 0 1 0 0 0 1 1\n",
      " 0 1 0 0 0 0 0 1 0 0 1 0 0 0 1 1 0 1 0 1 0 0 1 0 0 0 0 0 0 0 0 1 0 0 1 0 0\n",
      " 0 1 1 1 1 0 0 0 1 0 0 0 1 0 0 0 1 0 0 0 1 0 1 1 0 0 0 1 0 0 1 0 1 0 0 1 1\n",
      " 0 0 0 1 0 0 0 0 1 1 0 0 1 0 0 1 0 1 0 1 1 0 0 1 1 0 0 0 0 0 0 0 1 0 0 0 1\n",
      " 0 1 0 0 1 0 0 0 1 0 0 0 1 0 1 0 1 1 1 0 0 1 0 0 0 0 0 1 0 0 1 1 0 1 1 0 0\n",
      " 0 1 0 1 0 0 1 1 1 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 0 0 0 0\n",
      " 0 0 0 0 1 1 0 1 1 0 0 0 0 1 0 0 0 1 0 0 0 0 0 0 1 0 0 0 1 1 0 1 0 1 0 1 0\n",
      " 0 1 0 1 0 0 0 0 0 0 0 0 0 1 0 0 1 0 0 0 0 0 0 0 0 1 1 0 1 0 0 1 1 1 0 1 0\n",
      " 1 0 0 0 0 0 0 0 1 1 0 0 1 0 1 0 0 0 0 0 0 0 0 1 1 1 0 1 1 0 1 1 0 0 0 0 0\n",
      " 0 0 0 0 0 0 1 1 0 0 1 0 0 0 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 1\n",
      " 0 0 1 1 0 0 0 0 0 0 0 0 1 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 0 0 0 0 1 0 1\n",
      " 0 0 0 0 0 0 0 0 0 0 1 0 0 1]\n",
      "643\n"
     ]
    }
   ],
   "source": [
    "#Checking values array.\n",
    "print(checking_values.values)\n",
    "print(len(checking_values))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8102643856920684\n"
     ]
    }
   ],
   "source": [
    "score = accuracy_score(target_test, predictions_test)\n",
    "print(score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[414  32]\n",
      " [ 90 107]]\n"
     ]
    }
   ],
   "source": [
    "#Creating a confusion matrice.\n",
    "cm = confusion_matrix(target_test, predictions_test)\n",
    "print(cm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 648x648 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "#Seaborn heatmap of our confusion matrice.\n",
    "#Our highest values should lie on the diagonal if our model perform well the task.\n",
    "#This heatmap works better with bigger confusion matrices\n",
    "#(When you have to classify something divided in many categories.)\n",
    "plt.figure(figsize=(9,9))\n",
    "sns.heatmap(cm, annot=True, fmt='.3f',square=True, cmap='Blues_r')\n",
    "plt.ylabel='Actual label'\n",
    "plt.xlabel='Predicted label'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True positive: 414\n",
      "False positive: 32\n",
      "False negative: 90\n",
      "True negative: 107\n"
     ]
    }
   ],
   "source": [
    "#Extracting TruePositive, FalsePositive, FalseNegative and TrueNegative from our confusion matrice.\n",
    "tp, fp, fn, tn = confusion_matrix(target_test, predictions_test).ravel()\n",
    "print('True positive:', tp)\n",
    "print('False positive:', fp)\n",
    "print('False negative:', fn)\n",
    "print('True negative:', tn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification report: \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.82      0.93      0.87       446\n",
      "           1       0.77      0.54      0.64       197\n",
      "\n",
      "    accuracy                           0.81       643\n",
      "   macro avg       0.80      0.74      0.75       643\n",
      "weighted avg       0.81      0.81      0.80       643\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#Confusion matrice metrics.\n",
    "report= classification_report(target_test, predictions_test)\n",
    "print('Classification report: \\n', report)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Brief summarize. Task 5.\n",
    "5. Additional task: sanity check the model. \n",
    "\n",
    "Since previously I saved in checking_values variable the output of our testing dataset. I was able to compare the array from our predictions to the array of the real values.\n",
    "\n",
    "81% of accuracy on the test.\n",
    "\n",
    "Created a confusion matrice to see how many TruePositive, FalsePositive, FalseNegative and TrueNegative I had in my predictions and plotted the heatmap of them.\n",
    "\n",
    "Resulted into:\n",
    "True positive: 414\n",
    "False positive: 32\n",
    "False negative: 90\n",
    "True negative: 107\n",
    "\n",
    "In the end, I wanted to understand the precision, the recall and the f1-score of the model. Obtained using classification_report function.\n",
    "\n",
    "Classification report: \n",
    "               precision    recall  f1-score   support\n",
    "\n",
    "           0       0.82      0.93      0.87       446\n",
    "           1       0.77      0.54      0.64       197\n",
    "\n",
    "    accuracy                           0.81       643\n",
    "   macro avg       0.80      0.74      0.75       643\n",
    "weighted avg       0.81      0.81      0.80       643"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6936236391912908\n"
     ]
    }
   ],
   "source": [
    "#Dummy classification with DummyClassifier.\n",
    "from sklearn.dummy import DummyClassifier\n",
    "\n",
    "dummy= DummyClassifier(strategy='most_frequent', random_state=8)\n",
    "dummy.fit(features_train, target_train)\n",
    "dummy_score = dummy.score(features_test, target_test)\n",
    "\n",
    "print(dummy_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6936236391912908\n"
     ]
    }
   ],
   "source": [
    "#SVC score\n",
    "from sklearn.svm import SVC\n",
    "\n",
    "clf= SVC(kernel='rbf', C=1, gamma='auto').fit(features_train, target_train)\n",
    "clf_score = clf.score(features_test, target_test)\n",
    "print(clf_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DummyClassifier and SVC returs as the minimal quality we can archieve on those data.\n",
      "Since our Dummy value is 69% and the accuracy of our model 81% instead, the validity of the model is afterall, \"good\".\n"
     ]
    }
   ],
   "source": [
    "print('DummyClassifier and SVC returs as the minimal quality we can archieve on those data.')\n",
    "print('Since our Dummy value is 69% and the accuracy of our model 81% instead, the validity of the model is afterall, \"good\".')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# General conclusion.\n",
    "\n",
    "I analyzed a small dataset of 3000 records (that was already preprocessed), trying to build a model with the maximum possible accuracy to predict the plan of a certain customer. That could be ultra or non-ultra.\n",
    "\n",
    "After choosing, training and testing the model. I was able to obtain 81% of accuracy in my model. 74% of recall and 75% off f1-score. The model predicted 521 true values and 122 false values on a base of 643 records."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.8"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": true,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
